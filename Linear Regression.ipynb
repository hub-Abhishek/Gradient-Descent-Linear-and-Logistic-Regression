{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n",
      "Number of processors:  12\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import multiprocessing as mp\n",
    "import pprint\n",
    "\n",
    "print(sys.getrecursionlimit())\n",
    "sys.setrecursionlimit(10001)\n",
    "\n",
    "print(\"Number of processors: \", mp.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abhis\\Downloads\\New folder\\College\\Course Materials\\Sem 2\\Applied Machine Learning\\Assignments\\Assignment 1\\sgemm_product_dataset\n"
     ]
    }
   ],
   "source": [
    "cd sgemm_product_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(241600, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWG</th>\n",
       "      <th>NWG</th>\n",
       "      <th>KWG</th>\n",
       "      <th>MDIMC</th>\n",
       "      <th>NDIMC</th>\n",
       "      <th>MDIMA</th>\n",
       "      <th>NDIMB</th>\n",
       "      <th>KWI</th>\n",
       "      <th>VWM</th>\n",
       "      <th>VWN</th>\n",
       "      <th>STRM</th>\n",
       "      <th>STRN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SB</th>\n",
       "      <th>Run1 (ms)</th>\n",
       "      <th>Run2 (ms)</th>\n",
       "      <th>Run3 (ms)</th>\n",
       "      <th>Run4 (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.26</td>\n",
       "      <td>115.87</td>\n",
       "      <td>118.55</td>\n",
       "      <td>115.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>78.13</td>\n",
       "      <td>78.25</td>\n",
       "      <td>79.25</td>\n",
       "      <td>79.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>79.84</td>\n",
       "      <td>80.69</td>\n",
       "      <td>80.76</td>\n",
       "      <td>80.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>84.32</td>\n",
       "      <td>89.90</td>\n",
       "      <td>86.75</td>\n",
       "      <td>85.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>115.13</td>\n",
       "      <td>121.98</td>\n",
       "      <td>122.73</td>\n",
       "      <td>114.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MWG  NWG  KWG  MDIMC  NDIMC  MDIMA  NDIMB  KWI  VWM  VWN  STRM  STRN  SA  \\\n",
       "0   16   16   16      8      8      8      8    2    1    1     0     0   0   \n",
       "1   16   16   16      8      8      8      8    2    1    1     0     0   0   \n",
       "2   16   16   16      8      8      8      8    2    1    1     0     0   1   \n",
       "3   16   16   16      8      8      8      8    2    1    1     0     0   1   \n",
       "4   16   16   16      8      8      8      8    2    1    1     0     1   0   \n",
       "\n",
       "   SB  Run1 (ms)  Run2 (ms)  Run3 (ms)  Run4 (ms)  \n",
       "0   0     115.26     115.87     118.55     115.80  \n",
       "1   1      78.13      78.25      79.25      79.19  \n",
       "2   0      79.84      80.69      80.76      80.97  \n",
       "3   1      84.32      89.90      86.75      85.58  \n",
       "4   0     115.13     121.98     122.73     114.81  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"sgemm_product.csv\")\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Runtime'] = data[['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)']].sum(axis = 1)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizing(x):\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    x_scaled =pd.DataFrame(scaler.fit_transform(x))\n",
    "    x_scaled.columns = x.columns\n",
    "    return x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWG</th>\n",
       "      <th>NWG</th>\n",
       "      <th>KWG</th>\n",
       "      <th>MDIMC</th>\n",
       "      <th>NDIMC</th>\n",
       "      <th>MDIMA</th>\n",
       "      <th>NDIMB</th>\n",
       "      <th>KWI</th>\n",
       "      <th>VWM</th>\n",
       "      <th>VWN</th>\n",
       "      <th>STRM</th>\n",
       "      <th>STRN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SB</th>\n",
       "      <th>Run1 (ms)</th>\n",
       "      <th>Run2 (ms)</th>\n",
       "      <th>Run3 (ms)</th>\n",
       "      <th>Run4 (ms)</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.210997</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.277465</td>\n",
       "      <td>-0.275877</td>\n",
       "      <td>-0.268497</td>\n",
       "      <td>-0.275927</td>\n",
       "      <td>-0.274446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.210997</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.378085</td>\n",
       "      <td>-0.377918</td>\n",
       "      <td>-0.375101</td>\n",
       "      <td>-0.375228</td>\n",
       "      <td>-0.376589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.210997</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.373451</td>\n",
       "      <td>-0.371300</td>\n",
       "      <td>-0.371005</td>\n",
       "      <td>-0.370400</td>\n",
       "      <td>-0.371545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.210997</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.361311</td>\n",
       "      <td>-0.346319</td>\n",
       "      <td>-0.354757</td>\n",
       "      <td>-0.357895</td>\n",
       "      <td>-0.355077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.516757</td>\n",
       "      <td>-1.210997</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.753894</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-0.998054</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-0.741449</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.277817</td>\n",
       "      <td>-0.259305</td>\n",
       "      <td>-0.257159</td>\n",
       "      <td>-0.278612</td>\n",
       "      <td>-0.268229</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        MWG       NWG       KWG     MDIMC     NDIMC     MDIMA     NDIMB  KWI  \\\n",
       "0 -1.516757 -1.516757 -1.210997 -0.753894 -0.753894 -0.998054 -0.998054 -1.0   \n",
       "1 -1.516757 -1.516757 -1.210997 -0.753894 -0.753894 -0.998054 -0.998054 -1.0   \n",
       "2 -1.516757 -1.516757 -1.210997 -0.753894 -0.753894 -0.998054 -0.998054 -1.0   \n",
       "3 -1.516757 -1.516757 -1.210997 -0.753894 -0.753894 -0.998054 -0.998054 -1.0   \n",
       "4 -1.516757 -1.516757 -1.210997 -0.753894 -0.753894 -0.998054 -0.998054 -1.0   \n",
       "\n",
       "        VWM       VWN  STRM  STRN   SA   SB  Run1 (ms)  Run2 (ms)  Run3 (ms)  \\\n",
       "0 -0.741449 -0.741449  -1.0  -1.0 -1.0 -1.0  -0.277465  -0.275877  -0.268497   \n",
       "1 -0.741449 -0.741449  -1.0  -1.0 -1.0  1.0  -0.378085  -0.377918  -0.375101   \n",
       "2 -0.741449 -0.741449  -1.0  -1.0  1.0 -1.0  -0.373451  -0.371300  -0.371005   \n",
       "3 -0.741449 -0.741449  -1.0  -1.0  1.0  1.0  -0.361311  -0.346319  -0.354757   \n",
       "4 -0.741449 -0.741449  -1.0   1.0 -1.0 -1.0  -0.277817  -0.259305  -0.257159   \n",
       "\n",
       "   Run4 (ms)   Runtime  \n",
       "0  -0.275927 -0.274446  \n",
       "1  -0.375228 -0.376589  \n",
       "2  -0.370400 -0.371545  \n",
       "3  -0.357895 -0.355077  \n",
       "4  -0.278612 -0.268229  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalized = normalizing(data)\n",
    "data_normalized.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abhis\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2495: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "x_train ,x_test ,y_train , y_test = train_test_split(\n",
    "    data_normalized.drop(columns = ['Run1 (ms)','Run2 (ms)','Run3 (ms)','Run4 (ms)','Runtime']), \n",
    "    data_normalized['Runtime'], test_size=0.3,  random_state=100)\n",
    "\n",
    "x_train = sm.add_constant(x_train)\n",
    "x_test = sm.add_constant(x_test)\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "Defining the model calculation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_m(m, alpha, x, y, length):\n",
    "    return (m - alpha*(x.T @ (x @ m - y))/length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cost(m, x, y, length):\n",
    "    return sum((x @ m - y)**2)/(2*length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_desc(x, y, length, m, alpha, iters, costs, threshold = 0):\n",
    "    \n",
    "    for i in range(0,iters):\n",
    "        cost = calc_cost(m, x, y, length)[0]\n",
    "        costs.append(cost)\n",
    "        m = calc_m(m, alpha, x, y, length)\n",
    "        if i > 1 and (costs[len(costs) - 2] - costs[len(costs) - 1] <= threshold):\n",
    "            break\n",
    "    return [m, costs, i]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting the model for an initial alpha of 0.015, with 3500 iterations and not checking for any thresholds in the drop of costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "x = np.array(x_train)\n",
    "y = np.array(y_train)\n",
    "m = np.random.rand(x.shape[1],1)\n",
    "alpha = 0.015\n",
    "iters = 15000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "betas = grad_desc(x, y, len(x), m, alpha, iters, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_parameters(coeff, x, y):\n",
    "    \n",
    "    err = np.subtract(y, x@coeff)\n",
    "    #Calculating R2 = 1 - sse/sst    \n",
    "    sse = np.sum(err**2)\n",
    "    sst = np.sum((y - np.mean(y, axis = 0))**2)\n",
    "    r2 = 1 - (sse[0]/sst[0])\n",
    "    print(\"R2 of the estimated model: {}\".format(r2))\n",
    "    \n",
    "    \n",
    "    #Calculating Adj R2 = 1 - (1 - r2)*(n - 1)/(n - k - 1)\n",
    "    adj_r2 = 1 - (1 - r2)*(len(x) - 1)/(len(x) - len(coeff) - 1)\n",
    "    print(\"Adjusted R2 of the estimated model: {}\".format(adj_r2))\n",
    "    \n",
    "    #variable name, coeff, p val, t - stat, std errors\n",
    "    model_output = pd.DataFrame(columns = ['Variable', 'Coeff', 'Std Err', 'T- Val'])\n",
    "    df = len(x) - len(coeff) - 1\n",
    "    x_terms = np.sum(np.subtract(x, np.mean(x, axis = 0))**2, axis = 0)\n",
    "    for i in range(0, len(coeff)):\n",
    "        se = math.sqrt(sse[0]/df)/math.sqrt(x_terms[i] + sys.float_info.epsilon)\n",
    "        t  =coeff[i]/se\n",
    "        model_output.loc[i] = [x_terms.index[i], coeff[i][0], se, t[0]]\n",
    "    print('Model Output:\\n')\n",
    "    print(model_output)\n",
    "    \n",
    "    #Mean Absolute Error\n",
    "    mae = np.sum(abs(err))/len(x)\n",
    "    print('\\nMean Absolute Error: {}'.format(mae[0]))\n",
    "    \n",
    "    #Mean Squared Error\n",
    "    mse = np.sum(err**2)/len(x)\n",
    "    print('Mean Squared Error: {}'.format(mse[0]))\n",
    "    \n",
    "    #Mean Absolute Percentage Error\n",
    "    mape = 100 * np.sum(abs(1-err/y))/len(x)\n",
    "    print(\"Mean Absolute Percentage Error: {}%\".format(mape[0]))\n",
    "    \n",
    "    #Root Mean Squared Error\n",
    "    rmse = math.sqrt(np.sum(err**2)/len(x))\n",
    "    print(\"Root Mean Squared Error: {}\".format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of the estimated model: 0.4068957777988651\n",
      "Adjusted R2 of the estimated model: 0.4068431677876707\n",
      "Model Output:\n",
      "\n",
      "   Variable     Coeff       Std Err        T- Val\n",
      "0     const  0.001343  5.181112e+07  2.592144e-11\n",
      "1       MWG  0.381875  1.878062e-03  2.033348e+02\n",
      "2       NWG  0.354979  1.876522e-03  1.891684e+02\n",
      "3       KWG  0.111514  1.877123e-03  5.940700e+01\n",
      "4     MDIMC -0.355647  1.872333e-03 -1.899487e+02\n",
      "5     NDIMC -0.350679  1.876451e-03 -1.868842e+02\n",
      "6     MDIMA  0.027151  1.875658e-03  1.447522e+01\n",
      "7     NDIMB  0.028465  1.876924e-03  1.516552e+01\n",
      "8       KWI  0.032238  1.877354e-03  1.717201e+01\n",
      "9       VWM -0.005934  1.878165e-03 -3.159715e+00\n",
      "10      VWN -0.016586  1.881904e-03 -8.813218e+00\n",
      "11     STRM -0.011838  1.877352e-03 -6.305722e+00\n",
      "12     STRN  0.000031  1.877357e-03  1.669561e-02\n",
      "13       SA  0.052275  1.877352e-03  2.784516e+01\n",
      "14       SB  0.064890  1.877352e-03  3.456450e+01\n",
      "\n",
      "Mean Absolute Error: 0.47972895659654735\n",
      "Mean Squared Error: 0.5959984164340649\n",
      "Mean Absolute Percentage Error: 599.3179686439045%\n",
      "Root Mean Squared Error: 0.7720093370122313\n"
     ]
    }
   ],
   "source": [
    "model_parameters(betas[0], x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cost: 0.29799920821702885\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(betas[1])\n",
    "print('Final cost: {}\\n'.format(betas[1][len(betas[1]) - 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing with inbuilt ols regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>Runtime</td>     <th>  R-squared:         </th>  <td>   0.407</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th>  <td>   0.407</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>  <td>   8287.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 11 Feb 2020</td> <th>  Prob (F-statistic):</th>   <td>  0.00</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>05:45:09</td>     <th>  Log-Likelihood:    </th> <td>-1.9621e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>169120</td>      <th>  AIC:               </th>  <td>3.924e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>169105</td>      <th>  BIC:               </th>  <td>3.926e+05</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>      <td> </td>     \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.0013</td> <td>    0.002</td> <td>    0.715</td> <td> 0.474</td> <td>   -0.002</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MWG</th>   <td>    0.3819</td> <td>    0.002</td> <td>  182.493</td> <td> 0.000</td> <td>    0.378</td> <td>    0.386</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NWG</th>   <td>    0.3550</td> <td>    0.002</td> <td>  169.978</td> <td> 0.000</td> <td>    0.351</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KWG</th>   <td>    0.1115</td> <td>    0.002</td> <td>   57.226</td> <td> 0.000</td> <td>    0.108</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MDIMC</th> <td>   -0.3556</td> <td>    0.002</td> <td> -173.791</td> <td> 0.000</td> <td>   -0.360</td> <td>   -0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NDIMC</th> <td>   -0.3507</td> <td>    0.002</td> <td> -170.906</td> <td> 0.000</td> <td>   -0.355</td> <td>   -0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MDIMA</th> <td>    0.0272</td> <td>    0.002</td> <td>   13.405</td> <td> 0.000</td> <td>    0.023</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NDIMB</th> <td>    0.0285</td> <td>    0.002</td> <td>   14.035</td> <td> 0.000</td> <td>    0.024</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>KWI</th>   <td>    0.0322</td> <td>    0.002</td> <td>   17.172</td> <td> 0.000</td> <td>    0.029</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VWM</th>   <td>   -0.0059</td> <td>    0.002</td> <td>   -2.807</td> <td> 0.005</td> <td>   -0.010</td> <td>   -0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>VWN</th>   <td>   -0.0166</td> <td>    0.002</td> <td>   -7.840</td> <td> 0.000</td> <td>   -0.021</td> <td>   -0.012</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STRM</th>  <td>   -0.0118</td> <td>    0.002</td> <td>   -6.306</td> <td> 0.000</td> <td>   -0.016</td> <td>   -0.008</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>STRN</th>  <td> 3.134e-05</td> <td>    0.002</td> <td>    0.017</td> <td> 0.987</td> <td>   -0.004</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SA</th>    <td>    0.0523</td> <td>    0.002</td> <td>   27.845</td> <td> 0.000</td> <td>    0.049</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SB</th>    <td>    0.0649</td> <td>    0.002</td> <td>   34.564</td> <td> 0.000</td> <td>    0.061</td> <td>    0.069</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>128738.260</td> <th>  Durbin-Watson:     </th>  <td>   2.003</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>   <td> 0.000</td>   <th>  Jarque-Bera (JB):  </th> <td>2938587.785</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>            <td> 3.526</td>   <th>  Prob(JB):          </th>  <td>    0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>        <td>22.165</td>   <th>  Cond. No.          </th>  <td>    1.70</td>  \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                Runtime   R-squared:                       0.407\n",
       "Model:                            OLS   Adj. R-squared:                  0.407\n",
       "Method:                 Least Squares   F-statistic:                     8287.\n",
       "Date:                Tue, 11 Feb 2020   Prob (F-statistic):               0.00\n",
       "Time:                        05:45:09   Log-Likelihood:            -1.9621e+05\n",
       "No. Observations:              169120   AIC:                         3.924e+05\n",
       "Df Residuals:                  169105   BIC:                         3.926e+05\n",
       "Df Model:                          14                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.0013      0.002      0.715      0.474      -0.002       0.005\n",
       "MWG            0.3819      0.002    182.493      0.000       0.378       0.386\n",
       "NWG            0.3550      0.002    169.978      0.000       0.351       0.359\n",
       "KWG            0.1115      0.002     57.226      0.000       0.108       0.115\n",
       "MDIMC         -0.3556      0.002   -173.791      0.000      -0.360      -0.352\n",
       "NDIMC         -0.3507      0.002   -170.906      0.000      -0.355      -0.347\n",
       "MDIMA          0.0272      0.002     13.405      0.000       0.023       0.031\n",
       "NDIMB          0.0285      0.002     14.035      0.000       0.024       0.032\n",
       "KWI            0.0322      0.002     17.172      0.000       0.029       0.036\n",
       "VWM           -0.0059      0.002     -2.807      0.005      -0.010      -0.002\n",
       "VWN           -0.0166      0.002     -7.840      0.000      -0.021      -0.012\n",
       "STRM          -0.0118      0.002     -6.306      0.000      -0.016      -0.008\n",
       "STRN        3.134e-05      0.002      0.017      0.987      -0.004       0.004\n",
       "SA             0.0523      0.002     27.845      0.000       0.049       0.056\n",
       "SB             0.0649      0.002     34.564      0.000       0.061       0.069\n",
       "==============================================================================\n",
       "Omnibus:                   128738.260   Durbin-Watson:                   2.003\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          2938587.785\n",
       "Skew:                           3.526   Prob(JB):                         0.00\n",
       "Kurtosis:                      22.165   Cond. No.                         1.70\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = sm.OLS(y_train, x_train).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Y for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of the estimated model: 0.40878395181005145\n",
      "Adjusted R2 of the estimated model: 0.4086615704796964\n",
      "Model Output:\n",
      "\n",
      "   Variable     Coeff       Std Err        T- Val\n",
      "0     const  0.001343  5.131145e+07  2.617386e-11\n",
      "1       MWG  0.381875  2.837545e-03  1.345795e+02\n",
      "2       NWG  0.354979  2.842988e-03  1.248611e+02\n",
      "3       KWG  0.111514  2.840858e-03  3.925372e+01\n",
      "4     MDIMC -0.355647  2.858047e-03 -1.244371e+02\n",
      "5     NDIMC -0.350679  2.843234e-03 -1.233381e+02\n",
      "6     MDIMA  0.027151  2.846054e-03  9.539718e+00\n",
      "7     NDIMB  0.028465  2.841567e-03  1.001720e+01\n",
      "8       KWI  0.032238  2.840067e-03  1.135112e+01\n",
      "9       VWM -0.005934  2.837181e-03 -2.091677e+00\n",
      "10      VWN -0.016586  2.824190e-03 -5.872702e+00\n",
      "11     STRM -0.011838  2.840046e-03 -4.168263e+00\n",
      "12     STRN  0.000031  2.840088e-03  1.103615e-02\n",
      "13       SA  0.052275  2.840051e-03  1.840642e+01\n",
      "14       SB  0.064890  2.840046e-03  2.284812e+01\n",
      "\n",
      "Mean Absolute Error: 0.4764883673702025\n",
      "Mean Squared Error: 0.5844844271148155\n",
      "Mean Absolute Percentage Error: 770.5541599475556%\n",
      "Root Mean Squared Error: 0.7645158122071875\n"
     ]
    }
   ],
   "source": [
    "y_hat = x_test @ betas[0]\n",
    "model_parameters(betas[0], x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
